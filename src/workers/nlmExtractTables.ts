import { readFileSync, statSync } from 'fs'
import { UnrecoverableError } from 'bullmq'
import path from 'path'
import { mkdir } from 'fs/promises'

import { DiscordJob, DiscordWorker } from '../lib/DiscordWorker'
import { extractTablesFromJson, fetchPdf } from '../lib/pdfTools'
import { jsonToMarkdown } from '../lib/jsonExtraction'
import { openai } from '../lib/openai'
import { ParsedDocument } from '../lib/nlm-ingestor-schema'
import { QUEUE_NAMES } from '../queues'

class NLMExtractTablesJob extends DiscordJob {
  declare data: DiscordJob['data'] & {
    json: ParsedDocument
  }
}

const base64Encode = (filename: string) => {
  const data = readFileSync(path.resolve(filename)).toString('base64')
  return 'data:image/png;base64,' + data
}

const extractTextViaVisionAPI = async (
  {
    filename,
  }: {
    filename: string
  },
  context: string
) => {
  const result = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content:
          'You are a CSRD expert and will extract text from a PDF with extract from the tables.',
      },
      {
        role: 'user',
        content: `I have a PDF with couple of tables related to a company's CO2 emissions. Can you extract the text from screenshot. I will send you the screenshot extract the header and table contents and ignore the surrounding text if they are not related to the tables/graphs (such as header, description, footnotes or disclaimers). For missing values or skipped cells, always use a placeholder like "n.a.". Use Markdown format for the table(s), only reply with markdown. OK?`,
      },
      {
        role: 'assistant',
        content:
          'Sure. Sounds good. Send the screenhot and I will extract the table(s) and return in markdown format as accurately as possible without any other comment.',
      },
      {
        role: 'assistant',
        content:
          'This is previous table extracted from previous pages:' + context,
      },
      {
        role: 'user',
        content: [
          {
            type: 'image_url',
            image_url: { url: base64Encode(filename), detail: 'high' },
          },
        ],
      },
    ],
  })
  return result.choices[0].message.content
}

const searchTerms = [
  'co2',
  'GHG',
  'turnover',
  'revenue',
  'income',
  'employees',
  'FTE',
  'fiscal year',
  'summary',
  'utsl√§pp',
  'anst√§llda',
  'inkomster',
  'oms√§ttning',
  'v√§xthusgas',
  'koldioxid',
]
const nlmExtractTables = new DiscordWorker(
  QUEUE_NAMES.NLM_EXTRACT_TABLES,
  async (job: NLMExtractTablesJob) => {
    const { json, url } = job.data
    
    job.sendMessage('üîç S√∂ker efter relevanta tabeller...')

    try {
      const pdf = await fetchPdf(url)
      const outputDir = path.resolve('/tmp', 'garbo-screenshots')
      await mkdir(outputDir, { recursive: true })
      job.editMessage(`‚úÖ PDF nedladdad!`)
      
      job.log('Extracting pages...')
      const { pages } = await extractTablesFromJson(
        pdf,
        json,
        outputDir,
        searchTerms
      )

      job.sendMessage(
        `ü§ñ Hittade relevanta tabeller p√• ${pages.length} unika sidor.`
      )

      job.log(`Extracted ${pages.length} pages. Extracting tables...`)
      
      const tables: { page_idx: number; markdown: string }[] =
        await pages.reduce(async (resultsPromise, { pageNumber, filename }) => {
          const results = await resultsPromise
          if (statSync(filename).size === 0) {
            job.log(`‚ö†Ô∏è Skipping empty image: ${filename}`)
            return results
          }
          const lastPageMarkdown = results.at(-1)?.markdown || ''
          const markdown =
            (await extractTextViaVisionAPI({ filename }, lastPageMarkdown)) ??
            ''
          // TODO: Send to s3 bucket (images)
          return [
            ...results,
            {
              page_idx: Number(pageNumber - 1),
              markdown,
            },
          ]
        }, Promise.resolve([] as { page_idx: number; markdown: string }[]))

      job.log('Extracted tables: ' + tables.map((t) => t.markdown).join(', '))

      return {
        markdown:
          jsonToMarkdown(json) +
          '\n\n This is some of the important tables from the markdown with more precision:' +
          tables
            .map(
              ({ page_idx, markdown }) =>
                `\n#### Page ${page_idx}: 
                  ${markdown}`
            )
            .join('\n'),
      }
    } catch (error) {
      job.editMessage(`‚ùå Fel vid tolkning av PDF: ${error.message}`)
      throw new UnrecoverableError(`Download Failed: ${error.message}`)
    }
  }
)

export default nlmExtractTables
